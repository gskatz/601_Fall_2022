{
  "hash": "b7a61c4be20b54dcf7bf7d6e1079fa17",
  "result": {
    "markdown": "---\ntitle: \"Challenge 3 Instructions\"\nauthor: \"Erika Nagai\"\ndesription: \"Tidy Data: Pivoting\"\ndate: \"09/27/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_3\n  - animal_weights\n  - eggs\n  - australian_marriage\n  - usa_households\n  - sce_labor\n---\n\n\nInstalling useful packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1.  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\n2.  identify what needs to be done to tidy the current data\n3.  anticipate the shape of pivoted data\n4.  pivot the data into tidy format using `pivot_longer`\n\n## Read in data\n\nRead in one (or more) of the following datasets, using the correct R package and command.\n\n-   animal_weights.csv ⭐\n-   eggs_tidy.csv ⭐⭐ or organiceggpoultry.xls ⭐⭐⭐\n-   australian_marriage\\*.xls ⭐⭐⭐\n-   USA Households\\*.xlsx ⭐⭐⭐⭐\n-   sce_labor_chart_data_public.xlsx 🌟🌟🌟🌟🌟\n\nI'm using \"USA households\" dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\noriginal_data <- read_excel(\"_data/USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx\", skip = 4)\n\nhead(original_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  ...1      ...2   Total Under…¹ $15,0…² $25,0…³ $35,0…⁴ $50,0…⁵ $75,0…⁶ $100,…⁷\n  <chr>     <chr>  <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 ALL RACES <NA>      NA    NA      NA      NA      NA      NA      NA      NA  \n2 2019      128451   100     9.1     8       8.3    11.7    16.5    12.3    15.5\n3 2018      128579   100    10.1     8.8     8.7    12      17      12.5    15  \n4 2017 2    127669   100    10       9.1     9.2    12      16.4    12.4    14.7\n5 2017      127586   100    10.1     9.1     9.2    11.9    16.3    12.6    14.8\n6 2016      126224   100    10.4     9       9.2    12.3    16.7    12.2    15  \n# … with 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, Estimate...13 <dbl>,\n#   `Margin of error1 (±)...14` <dbl>, Estimate...15 <chr>,\n#   `Margin of error1 (±)...16` <chr>, and abbreviated variable names\n#   ¹​`Under $15,000`, ²​`$15,000\\r\\nto\\r\\n$24,999`, ³​`$25,000\\r\\nto\\r\\n$34,999`,\n#   ⁴​`$35,000\\r\\nto\\r\\n$49,999`, ⁵​`$50,000\\r\\nto\\r\\n$74,999`,\n#   ⁶​`$75,000\\r\\nto\\r\\n$99,999`, ⁷​`$100,000\\r\\nto\\r\\n$149,999`\n```\n:::\n:::\n\n\nThis data is very dirty and hard to read. Before start analyzing it, let's clean the data!\n\n## Anticipate the End Result\n\nAs \n\n1. Let's clean column names first\n\n::: {.cell}\n\n```{.r .cell-code}\ndata\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (..., list = character(), package = NULL, lib.loc = NULL, \n    verbose = getOption(\"verbose\"), envir = .GlobalEnv, overwrite = TRUE) \n{\n    fileExt <- function(x) {\n        db <- grepl(\"\\\\.[^.]+\\\\.(gz|bz2|xz)$\", x)\n        ans <- sub(\".*\\\\.\", \"\", x)\n        ans[db] <- sub(\".*\\\\.([^.]+\\\\.)(gz|bz2|xz)$\", \"\\\\1\\\\2\", \n            x[db])\n        ans\n    }\n    my_read_table <- function(...) {\n        lcc <- Sys.getlocale(\"LC_COLLATE\")\n        on.exit(Sys.setlocale(\"LC_COLLATE\", lcc))\n        Sys.setlocale(\"LC_COLLATE\", \"C\")\n        read.table(...)\n    }\n    stopifnot(is.character(list))\n    names <- c(as.character(substitute(list(...))[-1L]), list)\n    if (!is.null(package)) {\n        if (!is.character(package)) \n            stop(\"'package' must be a character vector or NULL\")\n    }\n    paths <- find.package(package, lib.loc, verbose = verbose)\n    if (is.null(lib.loc)) \n        paths <- c(path.package(package, TRUE), if (!length(package)) getwd(), \n            paths)\n    paths <- unique(normalizePath(paths[file.exists(paths)]))\n    paths <- paths[dir.exists(file.path(paths, \"data\"))]\n    dataExts <- tools:::.make_file_exts(\"data\")\n    if (length(names) == 0L) {\n        db <- matrix(character(), nrow = 0L, ncol = 4L)\n        for (path in paths) {\n            entries <- NULL\n            packageName <- if (file_test(\"-f\", file.path(path, \n                \"DESCRIPTION\"))) \n                basename(path)\n            else \".\"\n            if (file_test(\"-f\", INDEX <- file.path(path, \"Meta\", \n                \"data.rds\"))) {\n                entries <- readRDS(INDEX)\n            }\n            else {\n                dataDir <- file.path(path, \"data\")\n                entries <- tools::list_files_with_type(dataDir, \n                  \"data\")\n                if (length(entries)) {\n                  entries <- unique(tools::file_path_sans_ext(basename(entries)))\n                  entries <- cbind(entries, \"\")\n                }\n            }\n            if (NROW(entries)) {\n                if (is.matrix(entries) && ncol(entries) == 2L) \n                  db <- rbind(db, cbind(packageName, dirname(path), \n                    entries))\n                else warning(gettextf(\"data index for package %s is invalid and will be ignored\", \n                  sQuote(packageName)), domain = NA, call. = FALSE)\n            }\n        }\n        colnames(db) <- c(\"Package\", \"LibPath\", \"Item\", \"Title\")\n        footer <- if (missing(package)) \n            paste0(\"Use \", sQuote(paste(\"data(package =\", \".packages(all.available = TRUE))\")), \n                \"\\n\", \"to list the data sets in all *available* packages.\")\n        else NULL\n        y <- list(title = \"Data sets\", header = NULL, results = db, \n            footer = footer)\n        class(y) <- \"packageIQR\"\n        return(y)\n    }\n    paths <- file.path(paths, \"data\")\n    for (name in names) {\n        found <- FALSE\n        for (p in paths) {\n            tmp_env <- if (overwrite) \n                envir\n            else new.env()\n            if (file_test(\"-f\", file.path(p, \"Rdata.rds\"))) {\n                rds <- readRDS(file.path(p, \"Rdata.rds\"))\n                if (name %in% names(rds)) {\n                  found <- TRUE\n                  if (verbose) \n                    message(sprintf(\"name=%s:\\t found in Rdata.rds\", \n                      name), domain = NA)\n                  thispkg <- sub(\".*/([^/]*)/data$\", \"\\\\1\", p)\n                  thispkg <- sub(\"_.*$\", \"\", thispkg)\n                  thispkg <- paste0(\"package:\", thispkg)\n                  objs <- rds[[name]]\n                  lazyLoad(file.path(p, \"Rdata\"), envir = tmp_env, \n                    filter = function(x) x %in% objs)\n                  break\n                }\n                else if (verbose) \n                  message(sprintf(\"name=%s:\\t NOT found in names() of Rdata.rds, i.e.,\\n\\t%s\\n\", \n                    name, paste(names(rds), collapse = \",\")), \n                    domain = NA)\n            }\n            if (file_test(\"-f\", file.path(p, \"Rdata.zip\"))) {\n                warning(\"zipped data found for package \", sQuote(basename(dirname(p))), \n                  \".\\nThat is defunct, so please re-install the package.\", \n                  domain = NA)\n                if (file_test(\"-f\", fp <- file.path(p, \"filelist\"))) \n                  files <- file.path(p, scan(fp, what = \"\", quiet = TRUE))\n                else {\n                  warning(gettextf(\"file 'filelist' is missing for directory %s\", \n                    sQuote(p)), domain = NA)\n                  next\n                }\n            }\n            else {\n                files <- list.files(p, full.names = TRUE)\n            }\n            files <- files[grep(name, files, fixed = TRUE)]\n            if (length(files) > 1L) {\n                o <- match(fileExt(files), dataExts, nomatch = 100L)\n                paths0 <- dirname(files)\n                paths0 <- factor(paths0, levels = unique(paths0))\n                files <- files[order(paths0, o)]\n            }\n            if (length(files)) {\n                for (file in files) {\n                  if (verbose) \n                    message(\"name=\", name, \":\\t file= ...\", .Platform$file.sep, \n                      basename(file), \"::\\t\", appendLF = FALSE, \n                      domain = NA)\n                  ext <- fileExt(file)\n                  if (basename(file) != paste0(name, \".\", ext)) \n                    found <- FALSE\n                  else {\n                    found <- TRUE\n                    zfile <- file\n                    zipname <- file.path(dirname(file), \"Rdata.zip\")\n                    if (file.exists(zipname)) {\n                      Rdatadir <- tempfile(\"Rdata\")\n                      dir.create(Rdatadir, showWarnings = FALSE)\n                      topic <- basename(file)\n                      rc <- .External(C_unzip, zipname, topic, \n                        Rdatadir, FALSE, TRUE, FALSE, FALSE)\n                      if (rc == 0L) \n                        zfile <- file.path(Rdatadir, topic)\n                    }\n                    if (zfile != file) \n                      on.exit(unlink(zfile))\n                    switch(ext, R = , r = {\n                      library(\"utils\")\n                      sys.source(zfile, chdir = TRUE, envir = tmp_env)\n                    }, RData = , rdata = , rda = load(zfile, \n                      envir = tmp_env), TXT = , txt = , tab = , \n                      tab.gz = , tab.bz2 = , tab.xz = , txt.gz = , \n                      txt.bz2 = , txt.xz = assign(name, my_read_table(zfile, \n                        header = TRUE, as.is = FALSE), envir = tmp_env), \n                      CSV = , csv = , csv.gz = , csv.bz2 = , \n                      csv.xz = assign(name, my_read_table(zfile, \n                        header = TRUE, sep = \";\", as.is = FALSE), \n                        envir = tmp_env), found <- FALSE)\n                  }\n                  if (found) \n                    break\n                }\n                if (verbose) \n                  message(if (!found) \n                    \"*NOT* \", \"found\", domain = NA)\n            }\n            if (found) \n                break\n        }\n        if (!found) {\n            warning(gettextf(\"data set %s not found\", sQuote(name)), \n                domain = NA)\n        }\n        else if (!overwrite) {\n            for (o in ls(envir = tmp_env, all.names = TRUE)) {\n                if (exists(o, envir = envir, inherits = FALSE)) \n                  warning(gettextf(\"an object named %s already exists and will not be overwritten\", \n                    sQuote(o)))\n                else assign(o, get(o, envir = tmp_env, inherits = FALSE), \n                  envir = envir)\n            }\n            rm(tmp_env)\n        }\n    }\n    invisible(names)\n}\n<bytecode: 0x0000027b396d5ae8>\n<environment: namespace:utils>\n```\n:::\n\n```{.r .cell-code}\ndata <- original_data %>%\n  rename(\n    Year = ...1,\n    Total_Number = ...2,\n    Median_Income_Estimate = Estimate...13,\n    Median_Margin_Error = `Margin of error1 (±)...14`,\n    Mean_Income_Estimate = Estimate...15,\n    Mean_Margin_Error = `Margin of error1 (±)...16`)\n\ndata\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 383 × 16\n   Year    Total…¹ Total Under…² $15,0…³ $25,0…⁴ $35,0…⁵ $50,0…⁶ $75,0…⁷ $100,…⁸\n   <chr>   <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 ALL RA… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n 2 2019    128451    100     9.1     8       8.3    11.7    16.5    12.3    15.5\n 3 2018    128579    100    10.1     8.8     8.7    12      17      12.5    15  \n 4 2017 2  127669    100    10       9.1     9.2    12      16.4    12.4    14.7\n 5 2017    127586    100    10.1     9.1     9.2    11.9    16.3    12.6    14.8\n 6 2016    126224    100    10.4     9       9.2    12.3    16.7    12.2    15  \n 7 2015    125819    100    10.6    10       9.6    12.1    16.1    12.4    14.9\n 8 2014    124587    100    11.4    10.5     9.6    12.6    16.4    12.1    14  \n 9 2013 3  123931    100    11.4    10.3     9.5    12.5    16.8    12      13.9\n10 2013 4  122952    100    11.3    10.4     9.7    13.1    17      12.5    13.6\n# … with 373 more rows, 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, Median_Income_Estimate <dbl>,\n#   Median_Margin_Error <dbl>, Mean_Income_Estimate <chr>,\n#   Mean_Margin_Error <chr>, and abbreviated variable names ¹​Total_Number,\n#   ²​`Under $15,000`, ³​`$15,000\\r\\nto\\r\\n$24,999`, ⁴​`$25,000\\r\\nto\\r\\n$34,999`,\n#   ⁵​`$35,000\\r\\nto\\r\\n$49,999`, ⁶​`$50,000\\r\\nto\\r\\n$74,999`,\n#   ⁷​`$75,000\\r\\nto\\r\\n$99,999`, ⁸​`$100,000\\r\\nto\\r\\n$149,999`\n```\n:::\n\n```{.r .cell-code}\n#QUESTION: I manually renamed the column names instead of merging two rows (\"Mean income (dollars)\" + \"Estimate\") because I didn't find a way to do it. But this is not realistic if we have more columns. Any tips?\n```\n:::\n\n2. Let's look at the end of the data and clean if necessary.\n\n::: {.cell}\n\n```{.r .cell-code}\ntail(data,35)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 35 × 16\n   Year    Total…¹ Total Under…² $15,0…³ $25,0…⁴ $35,0…⁵ $50,0…⁶ $75,0…⁷ $100,…⁸\n   <chr>   <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 \"1975 … 2948      100    16.4    14.7    15      17.5    21.5     8.9     4.7\n 2 \"1974 … 2897      100    13      15.4    13.8    18      22.1    10.4     5.7\n 3 \"1973\"  2722      100    12.2    14.2    14      18.8    22.3    11.4     5.8\n 4 \"1972 … 2655      100    11.9    16      13.5    20.6    22.1     9.5     4.8\n 5 \"N Not… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n 6 \"1 A m… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n 7 \"2 Est… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n 8 \"3 The… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n 9 \"4 The… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n10 \"5 Imp… <NA>       NA    NA      NA      NA      NA      NA      NA      NA  \n# … with 25 more rows, 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, Median_Income_Estimate <dbl>,\n#   Median_Margin_Error <dbl>, Mean_Income_Estimate <chr>,\n#   Mean_Margin_Error <chr>, and abbreviated variable names ¹​Total_Number,\n#   ²​`Under $15,000`, ³​`$15,000\\r\\nto\\r\\n$24,999`, ⁴​`$25,000\\r\\nto\\r\\n$34,999`,\n#   ⁵​`$35,000\\r\\nto\\r\\n$49,999`, ⁶​`$50,000\\r\\nto\\r\\n$74,999`,\n#   ⁷​`$75,000\\r\\nto\\r\\n$99,999`, ⁸​`$100,000\\r\\nto\\r\\n$149,999`\n```\n:::\n:::\n\nWe can see that the last 31 rows are not part of data but notes, so we should drop them.\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- head(data, -31)\ntail(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  Year     Total…¹ Total Under…² $15,0…³ $25,0…⁴ $35,0…⁵ $50,0…⁶ $75,0…⁷ $100,…⁸\n  <chr>    <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1977     3304      100    13.7    14.8    14.1    18.2    20.8    10.6     6  \n2 1976 18  3081      100    16.2    15.3    13.6    18.1    20      10.3     5.1\n3 1975 19  2948      100    16.4    14.7    15      17.5    21.5     8.9     4.7\n4 1974 19… 2897      100    13      15.4    13.8    18      22.1    10.4     5.7\n5 1973     2722      100    12.2    14.2    14      18.8    22.3    11.4     5.8\n6 1972 21  2655      100    11.9    16      13.5    20.6    22.1     9.5     4.8\n# … with 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, Median_Income_Estimate <dbl>,\n#   Median_Margin_Error <dbl>, Mean_Income_Estimate <chr>,\n#   Mean_Margin_Error <chr>, and abbreviated variable names ¹​Total_Number,\n#   ²​`Under $15,000`, ³​`$15,000\\r\\nto\\r\\n$24,999`, ⁴​`$25,000\\r\\nto\\r\\n$34,999`,\n#   ⁵​`$35,000\\r\\nto\\r\\n$49,999`, ⁶​`$50,000\\r\\nto\\r\\n$74,999`,\n#   ⁷​`$75,000\\r\\nto\\r\\n$99,999`, ⁸​`$100,000\\r\\nto\\r\\n$149,999`\n```\n:::\n:::\n\n\n3. Clean \"Year\" column\n* \"Year\" column includes the information of racial classification as well. Make a new column that can contains it.\n* Change the order of columns\n* Drop the rows that have only racial classification information\n* Some values in the \"Year\" column includes the number for footnotes. Remove this number. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data %>%\n  mutate(race = str_extract(Year, \"^(\\\\D)+\")) %>% #extract only text data and create a new column that contains it\n  fill(race, .direction = 'down') %>% \n  select(race, Year, everything()) \n\ndata <- data[!(is.na(data$Total_Number)),]\ndata <- data[, colnames(data)!= \"Total\"]\n\n\n\nhead(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 16\n  race     Year  Total…¹ Under…² $15,0…³ $25,0…⁴ $35,0…⁵ $50,0…⁶ $75,0…⁷ $100,…⁸\n  <chr>    <chr> <chr>     <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 ALL RAC… 2019  128451      9.1     8       8.3    11.7    16.5    12.3    15.5\n2 ALL RAC… 2018  128579     10.1     8.8     8.7    12      17      12.5    15  \n3 ALL RAC… 2017… 127669     10       9.1     9.2    12      16.4    12.4    14.7\n4 ALL RAC… 2017  127586     10.1     9.1     9.2    11.9    16.3    12.6    14.8\n5 ALL RAC… 2016  126224     10.4     9       9.2    12.3    16.7    12.2    15  \n6 ALL RAC… 2015  125819     10.6    10       9.6    12.1    16.1    12.4    14.9\n# … with 6 more variables: `$150,000\\r\\nto\\r\\n$199,999` <dbl>,\n#   `$200,000 and over` <dbl>, Median_Income_Estimate <dbl>,\n#   Median_Margin_Error <dbl>, Mean_Income_Estimate <chr>,\n#   Mean_Margin_Error <chr>, and abbreviated variable names ¹​Total_Number,\n#   ²​`Under $15,000`, ³​`$15,000\\r\\nto\\r\\n$24,999`, ⁴​`$25,000\\r\\nto\\r\\n$34,999`,\n#   ⁵​`$35,000\\r\\nto\\r\\n$49,999`, ⁶​`$50,000\\r\\nto\\r\\n$74,999`,\n#   ⁷​`$75,000\\r\\nto\\r\\n$99,999`, ⁸​`$100,000\\r\\nto\\r\\n$149,999`\n```\n:::\n:::\n\n\n\n\n### Briefly describe the data\n\nThis data is about the annual income per U.S. household from 1967 to 2019 by the racial composition of that household.\nIt shows (1) Distribution of the income and (2) Median income (3) Mean income.\n\nThe name of columns \n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"race\"                       \"Year\"                      \n [3] \"Total_Number\"               \"Under $15,000\"             \n [5] \"$15,000\\r\\nto\\r\\n$24,999\"   \"$25,000\\r\\nto\\r\\n$34,999\"  \n [7] \"$35,000\\r\\nto\\r\\n$49,999\"   \"$50,000\\r\\nto\\r\\n$74,999\"  \n [9] \"$75,000\\r\\nto\\r\\n$99,999\"   \"$100,000\\r\\nto\\r\\n$149,999\"\n[11] \"$150,000\\r\\nto\\r\\n$199,999\" \"$200,000 and over\"         \n[13] \"Median_Income_Estimate\"     \"Median_Margin_Error\"       \n[15] \"Mean_Income_Estimate\"       \"Mean_Margin_Error\"         \n```\n:::\n:::\n\nRacial classifications include:\n\n::: {.cell}\n\n```{.r .cell-code}\nunique(data$race)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"ALL RACES\"                     \"WHITE ALONE \"                 \n [3] \"WHITE \"                        \"WHITE ALONE, NOT HISPANIC \"   \n [5] \"WHITE, NOT HISPANIC \"          \"BLACK ALONE OR IN COMBINATION\"\n [7] \"BLACK ALONE \"                  \"BLACK \"                       \n [9] \"ASIAN ALONE OR IN COMBINATION\" \"ASIAN ALONE \"                 \n[11] \"ASIAN AND PACIFIC ISLANDER \"   \"HISPANIC (ANY RACE) \"         \n```\n:::\n:::\n\n### Challenge: Describe the final dimensions\n\nThe current dataframe \"data\" includes several observations in the same row.\nLet's make this dataframe longer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# In order to use pivot_longer, the data type of the columns that will be combined need to be needs to be the same.\ndata$Total_Number <- as.numeric(data$Total_Number)\ndata$Mean_Income_Estimate <- as.numeric(data$Mean_Income_Estimate)\ndata$Mean_Margin_Error <- as.numeric(data$Mean_Margin_Error)\ndata$Median_Income_Estimate <- as.numeric(data$Median_Income_Estimate)\ndata$Median_Margin_Error <- as.numeric(data$Median_Margin_Error)\n\nstr(data$Total_Number)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n num [1:340] 128451 128579 127669 127586 126224 ...\n```\n:::\n\n```{.r .cell-code}\nlong_data <- pivot_longer(data, col = c(3:16),\n                         names_to = \"measure\",\n                         values_to = \"value\"\n                         ) \n\n  \nlong_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4,760 × 4\n   race      Year  measure                         value\n   <chr>     <chr> <chr>                           <dbl>\n 1 ALL RACES 2019  \"Total_Number\"               128451  \n 2 ALL RACES 2019  \"Under $15,000\"                   9.1\n 3 ALL RACES 2019  \"$15,000\\r\\nto\\r\\n$24,999\"        8  \n 4 ALL RACES 2019  \"$25,000\\r\\nto\\r\\n$34,999\"        8.3\n 5 ALL RACES 2019  \"$35,000\\r\\nto\\r\\n$49,999\"       11.7\n 6 ALL RACES 2019  \"$50,000\\r\\nto\\r\\n$74,999\"       16.5\n 7 ALL RACES 2019  \"$75,000\\r\\nto\\r\\n$99,999\"       12.3\n 8 ALL RACES 2019  \"$100,000\\r\\nto\\r\\n$149,999\"     15.5\n 9 ALL RACES 2019  \"$150,000\\r\\nto\\r\\n$199,999\"      8.3\n10 ALL RACES 2019  \"$200,000 and over\"              10.3\n# … with 4,750 more rows\n```\n:::\n:::\n\nThe dataframe is now cleaner, however it can be improved by the below ideas.\n* Replace \"'\\r\\nto\\r\\n'\" with \"to\"\n* The values in the following columns are proportion, not absolute number. So it may be better to consider them as one observation (because the total of these values is always 100) rather than consider these values as several observations.\n\"Under $15,000\" \"$15,000\\r\\nto\\r\\n$24,999\"   \"$25,000\\r\\nto\\r\\n$34,999\"   \"$35,000\\r\\nto\\r\\n$49,999\"   \"$50,000\\r\\nto\\r\\n$74,999\"  \n\"$75,000\\r\\nto\\r\\n$99,999\"   \"$100,000\\r\\nto\\r\\n$149,999\" \"$150,000\\r\\nto\\r\\n$199,999\" \"$200,000 and over\" \n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}