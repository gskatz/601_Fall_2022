{
  "hash": "33e16c56e11ddc844414b7ec870cd4e8",
  "result": {
    "markdown": "---\ntitle: \"Sarah McAlpine - Challenge 3\"\nauthor: \"Sarah McAlpine\"\ndesription: #Pivoting Data#\"\ndate: \"09/26/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_3\n  - sarahmcalpine\n  - eggs\n  - pivot_longer()\n  - rename()\n  - mutate()\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(summarytools)\n\nknitr::opts_chunk$set(echo = TRUE)\n```\n:::\n\n\n## Pivoting \"Tidy\" Egg Data\n\nFor this challenge, I will read in and pivot the eggs_tidy.csv data to prepare it for analysis.\n\nAfter looking at the rendered data frame summary, I know that there are 6 columns of data and 120 rows, containing all 12 months of the year, and the years 2004-2013. The remaining 4 columns are large_half_dozen, large_dozen, extra_large_half_dozen, and extra_large_dozen, all with their values ranging from 126-290. By researching the source of this data, I know that the values correspond to the price in cents, meaning that egg prices range from $1.26 to $2.90 for large and extra large half-dozens and dozens of eggs. While I read in the data, I will also rename the columns to separate the size and quantity variables for my next step. This will not change the dimensions of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in egg data and assign a name\neggs <- read_csv(\"_data/eggs_tidy.csv\") %>%\n  rename(\"xlarge_halfdozen\" = \"extra_large_half_dozen\", \n         \"xlarge_dozen\" = \"extra_large_dozen\", \n         \"large_halfdozen\" = \"large_half_dozen\") \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 120 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): month\ndbl (5): year, large_half_dozen, large_dozen, extra_large_half_dozen, extra_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nprint(dfSummary(eggs))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nData Frame Summary  \neggs  \nDimensions: 120 x 6  \nDuplicates: 0  \n\n-------------------------------------------------------------------------------------------------------------------\nNo   Variable           Stats / Values             Freqs (% of Valid)    Graph                 Valid      Missing  \n---- ------------------ -------------------------- --------------------- --------------------- ---------- ---------\n1    month              1. April                   10 ( 8.3%)            I                     120        0        \n     [character]        2. August                  10 ( 8.3%)            I                     (100.0%)   (0.0%)   \n                        3. December                10 ( 8.3%)            I                                         \n                        4. February                10 ( 8.3%)            I                                         \n                        5. January                 10 ( 8.3%)            I                                         \n                        6. July                    10 ( 8.3%)            I                                         \n                        7. June                    10 ( 8.3%)            I                                         \n                        8. March                   10 ( 8.3%)            I                                         \n                        9. May                     10 ( 8.3%)            I                                         \n                        10. November               10 ( 8.3%)            I                                         \n                        [ 2 others ]               20 (16.7%)            III                                       \n\n2    year               Mean (sd) : 2008.5 (2.9)   2004 : 12 (10.0%)     II                    120        0        \n     [numeric]          min < med < max:           2005 : 12 (10.0%)     II                    (100.0%)   (0.0%)   \n                        2004 < 2008.5 < 2013       2006 : 12 (10.0%)     II                                        \n                        IQR (CV) : 5 (0)           2007 : 12 (10.0%)     II                                        \n                                                   2008 : 12 (10.0%)     II                                        \n                                                   2009 : 12 (10.0%)     II                                        \n                                                   2010 : 12 (10.0%)     II                                        \n                                                   2011 : 12 (10.0%)     II                                        \n                                                   2012 : 12 (10.0%)     II                                        \n                                                   2013 : 12 (10.0%)     II                                        \n\n3    large_halfdozen    Mean (sd) : 155.2 (22.6)   126.00 :  1 ( 0.8%)                         120        0        \n     [numeric]          min < med < max:           128.50 : 29 (24.2%)   IIII                  (100.0%)   (0.0%)   \n                        126 < 174.5 < 178          129.75 :  1 ( 0.8%)                                             \n                        IQR (CV) : 45.1 (0.1)      131.00 :  3 ( 2.5%)                                             \n                                                   131.12!:  1 ( 0.8%)                                             \n                                                   132.00 : 15 (12.5%)   II                                        \n                                                   133.50 :  3 ( 2.5%)                                             \n                                                   173.25 :  6 ( 5.0%)   I                                         \n                                                   174.50 : 47 (39.2%)   IIIIIII                                   \n                                                   178.00 : 14 (11.7%)   II                                        \n                                                   ! rounded                                                       \n\n4    large_dozen        Mean (sd) : 254.2 (18.5)   12 distinct values                    :     120        0        \n     [numeric]          min < med < max:                                                 :     (100.0%)   (0.0%)   \n                        225 < 267.5 < 277.5                                :             :                         \n                        IQR (CV) : 34.5 (0.1)                              : .           : .                       \n                                                                         . : :           : :                       \n\n5    xlarge_halfdozen   Mean (sd) : 164.2 (24.7)   132.00 :  1 ( 0.8%)                         120        0        \n     [numeric]          min < med < max:           134.50 :  1 ( 0.8%)                         (100.0%)   (0.0%)   \n                        132 < 185.5 < 188.1        135.50 : 28 (23.3%)   IIII                                      \n                        IQR (CV) : 49.7 (0.2)      135.88!:  1 ( 0.8%)                                             \n                                                   137.00 :  6 ( 5.0%)   I                                         \n                                                   138.12!:  1 ( 0.8%)                                             \n                                                   139.00 : 15 (12.5%)   II                                        \n                                                   185.50 : 53 (44.2%)   IIIIIIII                                  \n                                                   188.13 : 14 (11.7%)   II                                        \n                                                   ! rounded                                                       \n\n6    xlarge_dozen       Mean (sd) : 266.8 (22.8)   11 distinct values              :           120        0        \n     [numeric]          min < med < max:                                   .       :           (100.0%)   (0.0%)   \n                        230 < 285.5 < 290                                  :       :                               \n                        IQR (CV) : 44 (0.1)                                :       :                               \n                                                                         . :       :                               \n-------------------------------------------------------------------------------------------------------------------\n```\n:::\n\n```{.r .cell-code}\n# quickly find mins, maxes, and ranges of data\nsummary(eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    month                year      large_halfdozen  large_dozen   \n Length:120         Min.   :2004   Min.   :126.0   Min.   :225.0  \n Class :character   1st Qu.:2006   1st Qu.:129.4   1st Qu.:233.5  \n Mode  :character   Median :2008   Median :174.5   Median :267.5  \n                    Mean   :2008   Mean   :155.2   Mean   :254.2  \n                    3rd Qu.:2011   3rd Qu.:174.5   3rd Qu.:268.0  \n                    Max.   :2013   Max.   :178.0   Max.   :277.5  \n xlarge_halfdozen  xlarge_dozen  \n Min.   :132.0    Min.   :230.0  \n 1st Qu.:135.8    1st Qu.:241.5  \n Median :185.5    Median :285.5  \n Mean   :164.2    Mean   :266.8  \n 3rd Qu.:185.5    3rd Qu.:285.5  \n Max.   :188.1    Max.   :290.0  \n```\n:::\n\n```{.r .cell-code}\n# preview first several rows\nhead(eggs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 6\n  month     year large_halfdozen large_dozen xlarge_halfdozen xlarge_dozen\n  <chr>    <dbl>           <dbl>       <dbl>            <dbl>        <dbl>\n1 January   2004            126         230              132          230 \n2 February  2004            128.        226.             134.         230 \n3 March     2004            131         225              137          230 \n4 April     2004            131         225              137          234.\n5 May       2004            131         225              137          236 \n6 June      2004            134.        231.             137          241 \n```\n:::\n:::\n\n\n## Predict Dimensions of Tidy Data \nIn considering this data set, I can expect one observation to include a month, a year, an egg size, and a quantity of eggs. Arranging the data in this way will allow analysis of price changes throughout the year and over time for both large and extra large eggs, as well as whether they are sold in dozens or half dozens. \n\nI expect the resulting data set to be four times as long since each size-quantity pairing will appear in its own row (rather than the initial 4 columns after month and year). I expect the total number of columns to reduce by one, since  I will remove the 4 size-quantity columns names and replace them with a column each for size, quantity, and average price. See below for this newly rearranged data.\n\n::: {.cell}\n\n```{.r .cell-code}\neggs_longer <- eggs %>%\n   pivot_longer(cols = contains(\"large\"),\n               names_to = c(\"size\", \"quantity\"),\n               names_sep = \"_\",\n               values_to = \"avg_price\")\n\neggs_longer\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 480 × 5\n   month     year size   quantity  avg_price\n   <chr>    <dbl> <chr>  <chr>         <dbl>\n 1 January   2004 large  halfdozen      126 \n 2 January   2004 large  dozen          230 \n 3 January   2004 xlarge halfdozen      132 \n 4 January   2004 xlarge dozen          230 \n 5 February  2004 large  halfdozen      128.\n 6 February  2004 large  dozen          226.\n 7 February  2004 xlarge halfdozen      134.\n 8 February  2004 xlarge dozen          230 \n 9 March     2004 large  halfdozen      131 \n10 March     2004 large  dozen          225 \n# … with 470 more rows\n```\n:::\n:::\n\n## Conclusion\nAs I predicted, I now have four times as many rows (120 became 480), and one column fewer (6 became 5). Now I have a single observation per row and am ready to begin analysis. I may wish to `mutate` the cents into dollars depending on the nature of my analysis or if there are other tables to bring in at some point. The preview tibble below rounds to whole cents, but the data retains the precise decimals.\n\n::: {.cell}\n\n```{.r .cell-code}\neggs_USD <- mutate(eggs_longer, \n       avg_USD = avg_price / 100\n       )%>%\n  select(!contains (\"price\"))\neggs_USD\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 480 × 5\n   month     year size   quantity  avg_USD\n   <chr>    <dbl> <chr>  <chr>       <dbl>\n 1 January   2004 large  halfdozen    1.26\n 2 January   2004 large  dozen        2.3 \n 3 January   2004 xlarge halfdozen    1.32\n 4 January   2004 xlarge dozen        2.3 \n 5 February  2004 large  halfdozen    1.28\n 6 February  2004 large  dozen        2.26\n 7 February  2004 xlarge halfdozen    1.34\n 8 February  2004 xlarge dozen        2.3 \n 9 March     2004 large  halfdozen    1.31\n10 March     2004 large  dozen        2.25\n# … with 470 more rows\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}