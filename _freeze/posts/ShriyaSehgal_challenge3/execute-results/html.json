{
  "hash": "e6b2cf511afbee833c9be3ce788b6b5f",
  "result": {
    "markdown": "---\ntitle: \"Challenge 3\"\nauthor: \"Shriya Sehgal\"\ndesription: \"Tidy Data: Pivoting\"\ndate: \"11/17/2022\"\nformat:\n  html:\n    toc: true\n    code-fold: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_3\n  - animal_weights\n  - eggs\n  - australian_marriage\n  - usa_households\n  - sce_labor\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n\n## Challenge Overview\n\nToday's challenge is to:\n\n1.  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)\n2.  identify what needs to be done to tidy the current data\n3.  anticipate the shape of pivoted data\n4.  pivot the data into tidy format using `pivot_longer`\n\n## Read in data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndataset <- read_csv(\"_data/eggs_tidy.csv\")\ndataset\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 120 × 6\n   month      year large_half_dozen large_dozen extra_large_half_dozen extra_l…¹\n   <chr>     <dbl>            <dbl>       <dbl>                  <dbl>     <dbl>\n 1 January    2004             126         230                    132       230 \n 2 February   2004             128.        226.                   134.      230 \n 3 March      2004             131         225                    137       230 \n 4 April      2004             131         225                    137       234.\n 5 May        2004             131         225                    137       236 \n 6 June       2004             134.        231.                   137       241 \n 7 July       2004             134.        234.                   137       241 \n 8 August     2004             134.        234.                   137       241 \n 9 September  2004             130.        234.                   136.      241 \n10 October    2004             128.        234.                   136.      241 \n# … with 110 more rows, and abbreviated variable name ¹​extra_large_dozen\n```\n:::\n:::\n\n\n### Briefly describe the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(eggs_dataset)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in summary(eggs_dataset): object 'eggs_dataset' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(eggs_dataset)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in head(eggs_dataset): object 'eggs_dataset' not found\n```\n:::\n:::\n\n\n\nThere are 129 rows and 6 columns containing the data of each month from the 2004-2013. The first 2 columns are the months and years and the rest 4 tells us the average price of the size and quantity of the eggs combined. The average price of the eggs ranges from 120-290 cents. The columns are as follows.\na. large_half_dozen\nb. extra_large_half_dozen\nc. large_dozen\nd. extra_large_dozen\n\n\n## Anticipate the End Result\n\nThe first step in pivoting the data is to try to come up with a concrete vision of what the end product *should* look like - that way you will know whether or not your pivoting was successful.\n\nOne easy way to do this is to think about the dimensions of your current data (tibble, dataframe, or matrix), and then calculate what the dimensions of the pivoted data should be.\n\nSuppose you have a dataset with $n$ rows and $k$ variables. In our example, 3 of the variables are used to identify a case, so you will be pivoting $k-3$ variables into a longer format where the $k-3$ variable names will move into the `names_to` variable and the current values in each of those columns will move into the `values_to` variable. Therefore, we would expect $n * (k-3)$ rows in the pivoted dataframe!\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#existing rows/cases\nnrow(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 120\n```\n:::\n\n```{.r .cell-code}\n#existing columns/cases\nncol(dataset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6\n```\n:::\n\n```{.r .cell-code}\n#expected rows/cases\nnrow(dataset) * (ncol(dataset)-2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 480\n```\n:::\n\n```{.r .cell-code}\n# expected columns \n3 + 2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n### Challenge: Describe the final dimensions\n\n\n\nIt can be seen that the dataset with 120 rows and 6 columns. After pivoting we would have the columns as months, year, size of the egg (large/extra large) and the quanity of the eggs(half dozen/dozen) which would make it extremely easy to observe the changes from 2004-2013 throughout the year for the size of the eggs as well as the quantity of eggs sold.\n\n\nThe resultant dataset would be 4 times larger than the original separating the size-quantity pairs with 4 columns. Another column that contains the information about the average price of the eggs have been added. So now, the total number of the columns would decrease by 1 and the resultants columns would be month, year, size, quantity and average price.\n\n## Pivot the Data\n\nNow we will pivot the data, and compare our pivoted data dimensions to the dimensions calculated above as a \"sanity\" check.\n\n### Example\n\n\n::: {.cell tbl-cap='Pivoted Example'}\n\n```{.r .cell-code}\ndataset_long <- dataset%>%\n  pivot_longer(cols=contains(\"large\"),\n               names_to = c(\"size\", \"quantity\"),\n               names_sep=\"_\",\n               values_to = \"cost\"\n  )\ndataset_long\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 480 × 5\n   month     year size  quantity  cost\n   <chr>    <dbl> <chr> <chr>    <dbl>\n 1 January   2004 large half      126 \n 2 January   2004 large dozen     230 \n 3 January   2004 extra large     132 \n 4 January   2004 extra large     230 \n 5 February  2004 large half      128.\n 6 February  2004 large dozen     226.\n 7 February  2004 extra large     134.\n 8 February  2004 extra large     230 \n 9 March     2004 large half      131 \n10 March     2004 large dozen     225 \n# … with 470 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#existing rows/cases after the pivot\nnrow(dataset_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 480\n```\n:::\n\n```{.r .cell-code}\n#existing columns/cases after the pivot\nncol(dataset_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n\nIt can been observed that the data is 4 times longer than the original dataset (120 to 480 rows) and the number of columns got reduced by 1. The process of pivoting makes the single observation per row and helps in easily understand the data and work for the future analysis.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}