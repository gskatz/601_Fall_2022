{
  "hash": "5c801d8de5f297b7cf5813bfbad355ce",
  "result": {
    "markdown": "---\ntitle: \"601_Final_Project\"\nauthor: \"Sahasra\"\ndate: '2022-12-18'\noutput: distill::distill_article\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the required packages\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(spotifyr)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in library(spotifyr): there is no package called 'spotifyr'\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(Dict)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in library(Dict): there is no package called 'Dict'\n```\n:::\n\n```{.r .cell-code}\nlibrary(reshape2)\nlibrary(stringi)\nlibrary(stringr)\nlibrary(hash)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in library(hash): there is no package called 'hash'\n```\n:::\n:::\n\n\n## Introduction \n\nSpotify is perhaps one of, if not the leading, music streaming service available today. It boasts of a wide variety of music genres in its coffins, and presently has over 456 million monthly active users, which includes 195 paying subscribers (as of September 2022). Spotify allows its users to create their own playlists, and also generates daily and weekly playlists, basis the streaming numbers of a certain genre or geographic region.\n\nIn this project, I have chosen to study the Top 50 Playlists of 4 countries - India, USA, France and Brazil. The music from these countries vary extremely in terms of their artists, as well as genres. What I aim to research through this project, is to find some similarities (if they exist) amongst these playlists, as this would suggest some sort of symphony across music as an art form, or if they vary, as this would mean that certain features exist that make the music originating from these countries distinctive to their audiences. \n\n## Data\n\nThe data being used in this project was not available beforehand and involved using Spotify's API to source the current data of the Top 50 Songs from each of the countries we chose. To start with I used the spotifyr wrapper package, to get different tracks and the attributes associated with them, relating to the features of songs, as well as details of the artists that created them and the genres that they belong to. The first step in accessing this Spotify data is to get an API key, which I created on the Spotify Developer Dashboard. The following code was used to get the Spotify access token : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Use client_id and secret token from developer dashboard to get access token\nid <- '4949e892016b49a988d0ceb6db9c8152'\nsecret <- '191ad5c5e32d4552a83d9e8eb95f1456'\nSys.setenv(SPOTIFY_CLIENT_ID = id)\nSys.setenv(SPOTIFY_CLIENT_SECRET = secret)\naccess_token <- get_spotify_access_token()\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in get_spotify_access_token(): could not find function \"get_spotify_access_token\"\n```\n:::\n:::\n\n\nWith the Spotify access token now available, I then manually added the 4 playlists to my own account, in order to carry out a filtered analysis on the playlists present in my account. \n\nWe now fetch the playlists saved in my Spotify account, using the code chunk below : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here I have used my unique Spotify user id to fetch the saved playlists on my Spotify account\noptions(httr_oauth_cache=T)\nuser_id <- 'u965216r0zoxby3bmbsxdsynm'\nuser_playlists <- get_user_playlists(user_id, limit = 20, offset = 0,\n  authorization = get_spotify_authorization_code(),\n  include_meta_info = FALSE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in get_user_playlists(user_id, limit = 20, offset = 0, authorization = get_spotify_authorization_code(), : could not find function \"get_user_playlists\"\n```\n:::\n:::\n\n\nThe variable user_playlists now contains all the playlists saved to my account. We will now filter the playlist of the Top 50 songs from the 4 countries we aim to analyse. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here, I have filtered the 4 playlist of interest\nfilter_user_playlists <- user_playlists %>%\n  filter(name %in% c('Top Songs - India','Top Songs - USA','Top Songs - Brazil','Top Songs - France'))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in filter(., name %in% c(\"Top Songs - India\", \"Top Songs - USA\", : object 'user_playlists' not found\n```\n:::\n:::\n\n\nWe will now use the function get_track_data for fetching the tracks that are contained in each of the 4 playlists. This is done by using the unique playlist id, associated with each of the playlists. As we are constructing a dataset, we are also mapping each track with the playlist that it is retrieved from, in order to ensure that in the occasion of an overlap, we know which playlist the track originated from. Along with the tracks within the playlists, we also get the audio features associated with each track. This consists of features such as danceability, acousticness, track length, etc. which we will discuss in further sections. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get_track_data - Function defined to get all the tracks within a playlist\nget_track_data <- function(index) {\n  features <- data.frame()\n  tracks <- data.frame()\n  upper_lim = index+1\n  for(i in index:upper_lim) {\n    playlist_tracks <- get_playlist_tracks(filter_user_playlists[i,\"id\"], authorization = get_spotify_access_token())\n    playlist_tracks$playlist_name <- filter_user_playlists[i, \"name\"]\n    tracks <- rbind2(tracks, playlist_tracks)\n    playlist_features <- get_track_audio_features(tracks$track.id, \n                                                        authorization = get_spotify_access_token())\n    features <- rbind2(features, playlist_features)\n  }\n  \n  return (list(tracks, features))\n}\n```\n:::\n\n\nThe code below fetches the tracks and associated audio features from the first 2 playlists from the filtered playlists, which are 'Top Songs - India' and 'Top Songs - USA'. We require to do this piecewise, as the function get_playlist_tracks has a predefined limit of fetching only 100 tracks per fetch call (sourced from the Spotify API documentation). \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntracks_f <- data.frame()\nfeatures_f <- data.frame()\n\n# Retrieve data of first 2 playlists\ndata <- get_track_data(1)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in get_playlist_tracks(filter_user_playlists[i, \"id\"], authorization = get_spotify_access_token()): could not find function \"get_playlist_tracks\"\n```\n:::\n\n```{.r .cell-code}\ntracks_f <- rbind2(tracks_f, data[[1]])\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in (function (cond) : error in evaluating the argument 'y' in selecting a method for function 'rbind2': object of type 'closure' is not subsettable\n```\n:::\n\n```{.r .cell-code}\nfeatures_f <- rbind2(features_f, data[[2]])\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in (function (cond) : error in evaluating the argument 'y' in selecting a method for function 'rbind2': object of type 'closure' is not subsettable\n```\n:::\n:::\n\n\nWe then fetch the tracks and audio features for the next 2 playlists, 'Top Songs - Brazil' and 'Top Songs - France'. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Retrieve data of last 2 playlists\ndata <- get_track_data(3)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in get_playlist_tracks(filter_user_playlists[i, \"id\"], authorization = get_spotify_access_token()): could not find function \"get_playlist_tracks\"\n```\n:::\n\n```{.r .cell-code}\ntracks_f <- rbind2(tracks_f, data[[1]])\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in (function (cond) : error in evaluating the argument 'y' in selecting a method for function 'rbind2': object of type 'closure' is not subsettable\n```\n:::\n\n```{.r .cell-code}\nfeatures_f <- rbind2(features_f, data[[2]])\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in (function (cond) : error in evaluating the argument 'y' in selecting a method for function 'rbind2': object of type 'closure' is not subsettable\n```\n:::\n\n```{.r .cell-code}\n# Rename uri column in features_f dataframe fo r subsequent join operation\nfeatures_f <- features_f %>%\n  rename(\"track.uri\" = \"uri\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `rename()`:\n! Can't rename columns that don't exist.\n✖ Column `uri` doesn't exist.\n```\n:::\n:::\n\n\nWe now have the consolidated tracks and features dataframes, which contains the tracks from all 4 playlists. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#tracks_f\n#features_f\n```\n:::\n\n\nWe will now do a left join on the tracks_f and featues_f dataframes on the track.uri column, to get our final dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Join operation to get final dataset\nall_tracks <- tracks_f%>%\n  left_join(features_f, by=\"track.uri\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `left_join()`:\n! Join columns must be present in data.\n✖ Problem with `track.uri`.\n```\n:::\n:::\n\n\n## Analysis and Visualization \n\nWe will first look at the different acoustic features of the tracks, namely danceability, speechiness, acousticness, energy and loudness. Let us first look at what each of these features convey about a song : \n\n1. Danceability: Describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity.\n\n2. Speechiness: This detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value.\n\n3. Acousticness: A confidence measure from 0.0 to 1.0 of whether the track is acoustic.\n\n4. Energy: Represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale.\n\n5. Loudness: The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks.\n\nWe only consider the above acoustic features, in the interest of looking at variables that show a degree of variation across the playlists, the visualizations of which are as below : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplots for visualizing danceability, energy and loudness across the 4 playlists\nfig_danceability <- plot_ly(all_tracks, y=~danceability, color = ~playlist_name, type = \"box\") %>% \n  layout(yaxis = list(title = c(\"Danceability\")))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig_energy <- plot_ly(all_tracks, y=~energy, color = ~playlist_name, type = \"box\", showlegend=FALSE) %>% \n  layout(yaxis = list(title = c(\"Energy\")))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig_loudness <- plot_ly(all_tracks, y=~loudness, color = ~playlist_name, type = \"box\", showlegend=FALSE) %>%\n  layout(yaxis = list(title = c(\"Loudness\")))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig <- subplot(fig_danceability, fig_energy, fig_loudness, nrows=3, titleY=TRUE) %>%\n  layout(title=list(text=\"Feature comparison across playlists\"),\n  plot_bgcolor='#e5ecf6', \n         xaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'),\n         yaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in dots2plots(...): object 'fig_danceability' not found\n```\n:::\n\n```{.r .cell-code}\nfig\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'fig' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplots for visualizing speechinessand acousticness across the 4 playlists\nfig_speechiness <- plot_ly(all_tracks, y=~speechiness, color = ~playlist_name, type = \"box\") %>%\n  layout(yaxis = list(title = c(\"Speechiness\")))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig_acousticness <- plot_ly(all_tracks, y=~acousticness, color = ~playlist_name, type = \"box\", showlegend=FALSE)  %>%\n  layout(yaxis = list(title = c(\"Acousticness\")))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig <- subplot(fig_speechiness, fig_acousticness, nrows=2, titleY=TRUE) %>%\n  layout(title=list(text=\"Feature comparison across playlists\"),\n  plot_bgcolor='#e5ecf6', \n         xaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'), \n         yaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in dots2plots(...): object 'fig_speechiness' not found\n```\n:::\n\n```{.r .cell-code}\nfig\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'fig' not found\n```\n:::\n:::\n\nFrom the boxplots above, we observe that the Brazil playlist has the highest number of danceable songs. Furthermore, Brazil, France and India have comparable energy coefficients for the tracks in their playlists, and USA has a slightly low track energy coefficient. In totality, however, France has the highest energy tracks (more compact boxplot). From the third boxplot, we observe that the same trend follows for loudness, which gives us the intuition that energy and loudness are perhaps correlated. Here however, Brazil has a more compact boxplot than France, which shows that the Brazil songs have a higher decibel level. We can perhaps anticipate some really upbeat songs in this playlist. \n\nThe speechiness plots vary across the 4 playlists, but we observe that India and USA have comparable medians, with France trailing behind closely. We can perhaps assume that the tracks here are composed of more music than words. I can't completely solidify the thought on the same, as there exist many outliers in this boxplot. \nFinally, the acousticness boxplot shows us that France has the least acoustic songs in its playlist. Again, as this is confidence based, we cannot arrive at conclusive results. \n\nLet us now visualize a heatmap for these acoustic features, to get a numeric value for their correlatedness. We construct the heatmap by computing correlation between the features, which is done using Pearson's method. The value ranges between -1 and 1. A value closer to 1 indicates a high correlation, and a value closer to -1 indicates that the 2 features are extremely uncorrelated. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Constructing the heatmap for checking correlation between acoustic features\ntrack_features <- all_tracks %>%\n  select(danceability, energy, loudness, speechiness, acousticness, instrumentalness, track.popularity, playlist_name) %>%\n  rename(\n    popularity = track.popularity\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., danceability, energy, loudness, speechiness, acousticness, : object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\ncor_mat <- cor(track_features[sapply(track_features, is.numeric)])\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(x): object 'track_features' not found\n```\n:::\n\n```{.r .cell-code}\nhm_data <- melt(cor_mat)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in melt(cor_mat): object 'cor_mat' not found\n```\n:::\n\n```{.r .cell-code}\nhm_data <- hm_data %>%\n  rename(\n    Features_x = Var1,\n    Features_y = Var2,\n    Index = value\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in rename(., Features_x = Var1, Features_y = Var2, Index = value): object 'hm_data' not found\n```\n:::\n\n```{.r .cell-code}\nhm_plot <- ggplot(hm_data,aes(x = Features_x, y = Features_y, fill = Index)) +\n  geom_tile() + \n  theme(axis.text.x=element_text(angle=45,hjust=1)) +\n  scale_fill_gradient(high = \"blue\", low = \"white\") \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(hm_data, aes(x = Features_x, y = Features_y, fill = Index)): object 'hm_data' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(hm_plot)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(hm_plot): object 'hm_plot' not found\n```\n:::\n:::\n\n\nThe color density for each feature measured against the other, gives us an estimate of the relatedness (or otherwise) of 2 features. \n\nFor instance, the darkest color gradient is present in the cross-section between loudness and energy, an intuition we previously had. It has a correlation coefficient of 0.709. Let us look at the loudness vs energy distribution plot. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot for Loudness vs Energy\noptions(dplyr.summarise.inform = FALSE)\n\ngroup_by_playlist <- all_tracks %>%\n  group_by(playlist_name) %>%\n  rename(\n    Playlist = playlist_name\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in group_by(., playlist_name): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig <- ggplot(group_by_playlist, aes(x=loudness, y=energy, color=Playlist, fill=Playlist, text=(paste(\"Loudness:\", loudness, \"<br>\", \"Energy:\", energy))), showlegend=FALSE)  +\n  geom_point() +\n  labs(\n    fill=\"Playlist\",\n    x=\"Loudness\",\n    y=\"Energy\"\n  ) + \n  facet_wrap(~Playlist) + \n  ggtitle(\"Loudness vs Energy\") \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(group_by_playlist, aes(x = loudness, y = energy, color = Playlist, : object 'group_by_playlist' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig): object 'fig' not found\n```\n:::\n:::\n\nFrom the above scatterplots, we can observe a similar behaviour across all 4 playlists. As the decibel of a track increases, so does its energy factor. \n\nTwo other features seem to have a higher color gradient that the rest, loudness and danceability. Their visualization is as below : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot for Loudness vs Danceability\nfig <- ggplot(group_by_playlist, aes(x=loudness, y=energy, color=Playlist, fill=Playlist, text=(paste(\"Loudness:\", loudness, \"<br>\", \"Danceability:\", danceability))), showlegend=FALSE)  +\n  geom_point() +\n  labs(\n    fill=\"Playlist\",\n    x=\"Loudness\",\n    y=\"Danceability\"\n  ) + \n  facet_wrap(~Playlist) + \n  ggtitle(\"Loudness vs Danceability\") \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(group_by_playlist, aes(x = loudness, y = energy, color = Playlist, : object 'group_by_playlist' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig): object 'fig' not found\n```\n:::\n:::\n\n\nAgain, we see an upward trend for these 2 acoustic features. So we can conclude that the playlists have a general trend of tracks having high decibels being considered to be more danceable. \n\nLet us now observe the heatmap from the lower side of the index spectrum. We can observe that the 2 features acousticness and danceability are almost white, with a correlation factor of -0.349. This shows us that they are inversely related. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot for Acousticness vs Danceability\nfig <- ggplot(group_by_playlist, aes(x=acousticness, y=energy, color=Playlist, fill=Playlist, text=(paste(\"Acousticness:\", acousticness, \"<br>\", \"Danceability:\", danceability))), showlegend=FALSE)  +\n  geom_point() +\n  labs(\n    fill=\"Playlist\",\n    x=\"Acousticness\",\n    y=\"Danceability\"\n  ) + \n  facet_wrap(~Playlist) + \n  ggtitle(\"Acousticness vs Danceability\") \n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(group_by_playlist, aes(x = acousticness, y = energy, color = Playlist, : object 'group_by_playlist' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig): object 'fig' not found\n```\n:::\n:::\n\nFrom the plots above, we do observe a tapering end at the lower right of each plot, which shows us that the two features do not follow a linear trend. \n\nFrom the plots so far, we see that danceability, energy and loudness are some key acoustic features within our playlists. Let us construct a distribution plot for each of these 3 features for our playlists. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Density plot for Danceability distribution\ngreen <- \"#1ed760\"\nyellow <- \"#e7e247\"\npink <- \"#ff6f59\"\nblue <- \"#17bebb\"\n\ndance_dist <- all_tracks %>%\n  rename(\n    Playlist = playlist_name\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in rename(., Playlist = playlist_name): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig <- ggplot(dance_dist, aes(x=danceability, fill=Playlist))+\n  geom_density(alpha=0.7, color=NA)+\n  scale_fill_manual(values=c(green, yellow, pink, blue))+\n  labs(x=\"Danceability\", y=\"Density\")+\n  theme_minimal()+\n  ggtitle(\"Distribution of Danceability\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(dance_dist, aes(x = danceability, fill = Playlist)): object 'dance_dist' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig, tooltip=c(\"text\"), showlegend=TRUE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig, tooltip = c(\"text\"), showlegend = TRUE): object 'fig' not found\n```\n:::\n:::\n\n\nThis graph suggests that of the 4 playlist, the USA playlist has the widest range of danceability in its Top 50 playlist. Further, we can also see that France's playlist consists of songs on the higher end of the danceability spectrum.\n\nWe will now plot the energy distribution across the 4 playlists : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Density plot for Energy distribution\nfig <- ggplot(dance_dist, aes(x=energy, fill=Playlist))+\n  geom_density(alpha=0.7, color=NA)+\n  scale_fill_manual(values=c(green, yellow, pink, blue))+\n  labs(x=\"Energy\", y=\"Density\")+\n  theme_minimal()+\n  ggtitle(\"Distribution of Energy\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(dance_dist, aes(x = energy, fill = Playlist)): object 'dance_dist' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig, tooltip=c(\"text\"), showlegend=TRUE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig, tooltip = c(\"text\"), showlegend = TRUE): object 'fig' not found\n```\n:::\n:::\n\nWe observe that India and US have the widest range of energy amongst the 4 playlists. US has extremely few tracks with high energy coefficient in its playlist, compared to the other 3, which was also what we observed in the boxplots plotted previously. Also, France's Top 50 playlist is mostly made up of songs on the higher end of the energy spectrum, which was a similar observation in our boxplots. \n\nWe will now plot the loudness distribution across the 4 playlists : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Density plot for Loudness distribution\nfig <- ggplot(dance_dist, aes(x=loudness, fill=Playlist))+\n  geom_density(alpha=0.7, color=NA)+\n  scale_fill_manual(values=c(green, yellow, pink, blue))+\n  labs(x=\"Loudness\", y=\"Density\")+\n  theme_minimal()+\n  ggtitle(\"Distribution of Loudness\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(dance_dist, aes(x = loudness, fill = Playlist)): object 'dance_dist' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig, tooltip=c(\"text\"), showlegend=TRUE)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig, tooltip = c(\"text\"), showlegend = TRUE): object 'fig' not found\n```\n:::\n:::\n\n\nFrom the density plot, we observe that the US, Brazil and France playlists have some really high decibel songs, of which Brazil is the clear winner, which is very similar to our observation with the boxplots. While the Indian playlist has many high decibel songs towards the higher end of the spectrum, it doesn't contain any with the decibel levels as high as the other 3. \n\n\nApart from these main acoustic features, I also analyzed the track popularity feature against danceability. This stemmed from the simple intuition that popular tracks could perhaps have danceable tunes. The visualization of the same is as below : \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Scatterplot for Popularity vs Danceability\noptions(dplyr.summarise.inform = FALSE)\n\ngroup_by_danceability <- all_tracks %>%\n  group_by(playlist_name, track.popularity) %>%\n  summarise(\n    mean_d = mean(danceability)\n  ) %>%\n  rename(\n    Playlist = playlist_name\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in group_by(., playlist_name, track.popularity): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig <- ggplot(group_by_danceability, aes(x=track.popularity, y=mean_d, color=Playlist, text=(paste(\"Popularity:\", track.popularity, \"<br>\", \"Danceability:\", mean_d))))  +\n  geom_point() +\n  labs(\n    x=\"Popularity\",\n    y=\"Danceability\",\n    fill=\"Playlist\"\n  ) +\n  facet_wrap(~Playlist) + \n  ggtitle(\"Popularity vs Danceability\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(group_by_danceability, aes(x = track.popularity, y = mean_d, : object 'group_by_danceability' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig): object 'fig' not found\n```\n:::\n:::\n\nPopularity is measured on a scale between 0 and 100, where 100 is the best. Per my intuition, the plots towards the right end of the scatter plots should have then had a higher danceability factor. However, the scatter plots we observe are completely random, exhibiting no significant relationship between the 2 variables. \n\nAn interesting acoustic feature that is unexplored so far is speechiness. As per the documentation, speechiness refers to the presence of spoken words in a song. Songs with a speechiness score between 0.33 and 0.66 contain both music and speech; they could be rap songs, for example. Based on this, we’re going to look at speechiness based on the difference between the speechiness score and 0.33. If the difference is above 0, it’s most likely a rap song. The farther below 0, the more instrumental the track is. \nWe will first use mutate to create a new column  that calculates the speechiness difference score by subtracting 0.33 from the speechiness column. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Mutate column for getting difference\nall_tracks <- all_tracks %>%\n  mutate(difference=speechiness - 0.33)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., difference = speechiness - 0.33): object 'all_tracks' not found\n```\n:::\n:::\n\n\nWe will now plot the graph to observe how many bars go above or below zero, which will show us the speechiness of each track in the playlists. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot for checking speechiness bars for all tracks\nfig <- ggplot(all_tracks, aes(x=reorder(track.name, -difference), y=difference, fill=playlist_name, text=(paste(\"Track:\", track.name, \"<br>\",\"Speechiness:\", speechiness))))+\n  geom_col()+\n  scale_fill_manual(values=c(green, yellow, pink, blue)) +\n  theme_minimal()+\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank(),\n        axis.ticks.y=element_blank(),\n        panel.grid.major = element_blank())+\n  ylab(\"Speechiness Difference\")+\n  labs(\n    fill=\"Playlist\"\n  ) +\n  facet_wrap(~playlist_name)+\n  ggtitle(\"Speechiness Difference\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(all_tracks, aes(x = reorder(track.name, -difference), : object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig, tooltip=c(\"text\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig, tooltip = c(\"text\")): object 'fig' not found\n```\n:::\n:::\n\nBrazil has more bars above 0, than any of the other countries. Furthermore, France has 3 distinct tracks, with a significant speechiness index in them. \n\"Baile No Morro\" is the speechiest song in the Brazil playlist with a speechiness of 0.453 and France's speechiest song is \"Canette dans les mains\" with a speechiness of 0.4.\nIndia and US have lesser bars above 0, and also a smaller speechiness index comapred to the other 2 countries. \n\nMoving on, we will now explore key, which describes the scale on which a song is based. This essentially means thta most of the notes in a song will come from the scale of that key. \n\nFor the purpose of representing this graphically, I created the below dataframe to find out how many songs from each playlist are in certain keys and the total number of songs in each key : \n\n::: {.cell}\n\n```{.r .cell-code}\n# Dataframe for getting key composition in tracks\nkey_by_country <- all_tracks%>%\n  select(playlist_name, key)%>%\n  group_by(playlist_name, key)%>%\n  mutate(n=n())%>%\n  unique()%>%\n  group_by(key)%>%\n  mutate(total=sum(n))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., playlist_name, key): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\n  #mutate(percent=round((n/total)*100))\n\nhead(key_by_country, 10)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in head(key_by_country, 10): object 'key_by_country' not found\n```\n:::\n:::\n\nWe now graph which keys are comprised in each of the playlists. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Renaming playlist_name for purpose of simplicity\nkey_by_country <- key_by_country %>%\n  rename(\n    Playlist = playlist_name\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in rename(., Playlist = playlist_name): object 'key_by_country' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Stacked bar chart for musical key proportions\nfig <- ggplot(key_by_country, aes(x=key, fill=Playlist, y = n, color = Playlist, \n                                text = paste(\"Number of Songs: \", n, \"<br>\")))+\n  geom_bar(position=\"fill\", width=0.5, stat = \"identity\")+\n  labs(x=\"Key\", y=\"Number of Songs\", fill=\"Playlist\")+\n  guides(fill=guide_legend(title=\"Playlist\"))+\n  theme_minimal()+\n  ggtitle(\"Musical Key Proportions by Playlist\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplot(key_by_country, aes(x = key, fill = Playlist, y = n, color = Playlist, : object 'key_by_country' not found\n```\n:::\n\n```{.r .cell-code}\nggplotly(fig, tooltip=c(\"text\"))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ggplotly(fig, tooltip = c(\"text\")): object 'fig' not found\n```\n:::\n:::\n\n\nFrom the stacked graph, we observe that no single key has an even distribution for all 4 playlists. Furthermore, we also observe that Indian tracks are dominated by the higher keys and songs from France use the middle-order keys extensively. \n\nWe will now try to incorporate and analyse one of the most widely associated attributes with music data - genre. Obtaining the genre data was relatively difficult for this dataset, as Spotify does not provide tags for genres for each individual track. The genre typically comes from the artist who composed the song, and the genres associated with them. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get_artist_name_id - Function to fetch artist name and artist id\nget_artist_name_id <- function(df){\n  for (i in 1:nrow(df)){\n        df[i, \"artist_name\"] <- list(df$track.artists[[i]]$name)\n        df[i, \"artist_id\"] <- list(df$track.artists[[i]]$id)\n    } \n  return(df)\n}\n\n# get_track_genre - Function to get genres associated with each track\nget_track_genre <- function(df){\n  for(i in 1:nrow(df)){\n    get_artists_op <- get_artists(df[i, \"artist_id\"], \n                                  authorization = get_spotify_access_token())\n    df[i, \"genre\"] <- stri_paste(unlist(get_artists_op$genre), collapse=',')\n  }\n  return(df)\n}\n```\n:::\n\n\nAs a first step, we will fetch the artist name and artist_id, which will be required to further query and get the genre data. \nWe then use this data to call the get_artists() API, which uses the artist's id to get the genres associated with that artist. Some artists do not have any genres associated with them, we list them as \"unlisted\" in the interest of getting genre proportions. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fetch data to get genres mapped to each track\nfilter_all_tracks <- all_tracks %>%\n  select(track.id, track.name, track.artists, duration_ms, track.uri, playlist_name)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in select(., track.id, track.name, track.artists, duration_ms, track.uri, : object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nall_tracks_with_artist <- get_artist_name_id(filter_all_tracks)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in nrow(df): object 'filter_all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nall_tracks_with_genres <- get_track_genre(all_tracks_with_artist)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in nrow(df): object 'all_tracks_with_artist' not found\n```\n:::\n\n```{.r .cell-code}\nall_tracks_with_genres$genre <- ifelse(all_tracks_with_genres$genre==\"\", \"unlisted\", all_tracks_with_genres$genre)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in ifelse(all_tracks_with_genres$genre == \"\", \"unlisted\", all_tracks_with_genres$genre): object 'all_tracks_with_genres' not found\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#head(all_tracks_with_genres)\n```\n:::\n\nThe genres are now available as comma separated values. For plotting a pie chart, we require a mapped set of the frequency of occurrence of each genre across the 4 playlists. I've written the below code chunk for creating a list with frequency counts. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create list for getting frequency count of genres across all tracks\ngenre_dict <- list()\n\nfor(i in 1:nrow(all_tracks_with_genres)){\n  if(!is.null(all_tracks_with_genres[i, \"genre\"])){\n    x <- str_split(all_tracks_with_genres[i, \"genre\"], \",\")\n    for(j in 1:length(x[[1]])){\n      if(!x[[1]][j] %in% names(genre_dict)){\n        genre_dict[[x[[1]][j]]] <- as.numeric(1)\n      } else {\n        vals <- genre_dict[[x[[1]][j]]]\n        genre_dict[[x[[1]][j]]] <- (as.numeric(vals)+1)\n      }\n    }\n  } else {\n    next\n  }\n}\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in nrow(all_tracks_with_genres): object 'all_tracks_with_genres' not found\n```\n:::\n:::\n\n\nFinally, we create a dataframe in the interest of simplicity from the list above, to plot a pie chart. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Transform list to dataframe for plotting pie chart\ngenre_counts <- data.frame()\ngenre_counts <- data.frame(genre_dict)\ncol_names = names(genre_counts)\n\ngenre_counts <- genre_counts %>%\n  pivot_longer(\n    cols = col_names,\n    names_to = \"features\",\n    values_to = \"counts\",\n    values_drop_na = TRUE\n  )\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in `build_longer_spec()`:\n! `cols` must select at least one column.\n```\n:::\n\n```{.r .cell-code}\nplot_ly(genre_counts,values=~counts,labels=~factor(features),marker=list(colors=c('#FF7F0E', '#1F77B4')),type=\"pie\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, data, expr_env): object 'counts' not found\n```\n:::\n:::\n\n\nThis plot gives us a distribution of the genres for all tracks across all 4 playlists. We can see that 'pop' has the highest proportion amongst all tracks, with almost 10% representation, followed by 'dance.pop' with almost 6% tracks. \n\nThe initial effort was to create this pie chart grouped by playlist, however, implementing frequency counts and playlist name mapping became increasingly complex. \n\nOne last feature I analysed was track duration. The track duration was avialble in milliseconds, so I decided to first convert it to minutes to get a better idea for comparability. Below is the visualization of track durations across the 4 playlists. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot for track duration (in mins) for the 4 playlists\nall_tracks_min <- all_tracks %>%\n  mutate(duration_mins = duration_ms/60000)\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in mutate(., duration_mins = duration_ms/60000): object 'all_tracks' not found\n```\n:::\n\n```{.r .cell-code}\nfig_time_duration <- plot_ly(all_tracks_min, y=~duration_mins, color = ~playlist_name, type = \"box\") %>% \n  layout(yaxis = list(title = c(\"Track Duration\")))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in is.data.frame(data): object 'all_tracks_min' not found\n```\n:::\n\n```{.r .cell-code}\nfig <- subplot(fig_time_duration, nrows=1, titleY=TRUE) %>%\n  layout(title=list(text=\"Time Duration across Playlists\"),\n  plot_bgcolor='#e5ecf6', \n         xaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'),\n         yaxis = list( \n           zerolinecolor = '#ffff', \n           zerolinewidth = 2, \n           gridcolor = 'ffff'))\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in dots2plots(...): object 'fig_time_duration' not found\n```\n:::\n\n```{.r .cell-code}\nfig\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in eval(expr, envir, enclos): object 'fig' not found\n```\n:::\n:::\n\nWe can see that Indian songs in general have longer tracks, followed by USA. Brazil has a very compact range of track duration, ranging from 2 to ~3.5 minutes. \n\n## Reflection\n\nProcuring, analysing, cleaning and visualizing data is a part of the day-to-day of any aspiring Data Scientist. This particular project was fascinating, yet challenging in terms of the data that it presented. Understanding the nuances of each acoustic feature, and the limitations of the Spotify wrapper was a whole new learning curve. \nThe Spotify wrapper presents a wide array of data. I think, perhaps, sticking to analyzing global playlists, instead of certain curated playlists, could have perhaps brought down the interestingness of the visualizations. However, I made the decision to analyze globally curated playlists to be backed by numbers, and not simply go on analyzing data on the basis on intuition. \n\nAother decision that I made to primariliy focus on the acoustic features, and not on other aspects, such as album statistics, or artists that fetaure in multiple playlists, was done in the interest of maintaining the aesthetics of the visualizations. \n\nAs previously mentioned, the most challenging part about this project was understanding how to procure the data, dabble with and gain an understanding of the different acoustic features, and generate a variety of visualizations.\n\nIf I could carry on with this project, I would delve deeper into podcasts as a category, and try to analyse the acoustic features in podcast playlists. The Spotify wrapper also has API calls such as 'get_recommendations()', which essentially creates a playlist-style listening experience based on seed artists, tracks and genres. I would have wanted to experiment with recommendations, basis the Top 50 artists and tracks, and see what insights could be gained from the same. \n\nIn essence, I believe the Spotify package has some amazing API functions, and I would have liked to deep-dive into that documentation to have a more well-rounded project. \n\n## Conclusion\n\nThis project revolved around the Spotify data of the Top 50 tracks from 4 countries, namely, India, USA, Brazil and France. I chose these 4 countries very intuitively on the basis of the music that I personally have heard from these 4 countries, and know them to be extremely varied. Through the course of this project, I discovered that certain musical similarities do exists between the  tracks from the different countries. \n\nOur initial analysis involved looking at the danceability, energy, loudness, acousticness and speechiness of the tracks. We observed that Brazil has the highest number of danceable songs, which was backed by the density distribution plot, France has a high energy factor in their Top 50 tracks, which was confirmed by the energy distribution plot and that the Brazilian songs have higher decibel levels than songs from the other playlists (which was also supported by the loudness density plot).\n\nFurther, our heatmap suggested that loudness and energy have a likely linear relationship, which we observed via the scatterplot. The heatmap also suggested an inverse relationship between acousticness and danceability. Both of these conclusions intuitively make sense, as higher decibel music typically requires a greater energy performance, thus inciting a similar response. Also, it is not typical to seek out soft, acoustic covers when one is looking for some numbers to dance on, which supplements the inverse relationship. \n\nWe also observed that popularity bears no significance on the danceability of a track. We also delved into the speechiness of a track, where we went with the assumption that any track having speechiness difference > 0.33 would typically be classified to be a rap song, and saw the representation of speechiness across the 4 playlists. We also looked at the musical key composition of all 4 playlists.\n\nFinally, we looked at the genres of the tracks present in these playlists, which required extensive coding. We saw that pop and dance pop were the most popular genres. \n\nIt must be noted that this data was relevant as of 16th December, 2022. Given the volatility of these charts, the above analysis stands good for the data as of above mentioned date. There is a possibility that the playlists have since seen changes in tracks, which could perhaps affect the results of this analysis. \n\n## Bibliography \n\n- https://cran.r-project.org/web/packages/tinyspotifyr/tinyspotifyr.pdf - The Spotifyr wrapper documentation\n- https://towardsdatascience.com/what-makes-a-song-likeable-dbfdb7abe404 - Audio features definitions\n- https://www.rcharlie.com/spotifyr/ - Spotifyr package usage website\n- https://plotly.com/r/ - Plotly R Open Sourcing Graphing Library\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}