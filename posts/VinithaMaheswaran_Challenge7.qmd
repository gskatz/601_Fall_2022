---
title: "Challenge 7 Solutions"
author: "Vinitha Maheswaran"
description: "Visualizing Multiple Dimensions"
date: "12/03/2022"
format:
  html:
    toc: true
    code-copy: true
    code-tools: true
categories:
  - challenge_7
  - hotel_bookings
  - australian_marriage
  - air_bnb
  - eggs
  - abc_poll
  - faostat
  - usa_households
---

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

Today's challenge is to:

1)  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)
2)  tidy data (as needed, including sanity checks)
3)  mutate variables as needed (including sanity checks)
4)  Recreate at least two graphs from previous exercises, but introduce at least one additional dimension that you omitted before using ggplot functionality (color, shape, line, facet, etc) The goal is not to create unneeded [chart ink (Tufte)](https://www.edwardtufte.com/tufte/), but to concisely capture variation in additional dimensions that were collapsed in your earlier 2 or 3 dimensional graphs.
   - Explain why you choose the specific graph type
5) If you haven't tried in previous weeks, work this week to make your graphs "publication" ready with titles, captions, and pretty axis labels and other viewer-friendly features

[R Graph Gallery](https://r-graph-gallery.com/) is a good starting point for thinking about what information is conveyed in standard graph types, and includes example R code. And anyone not familiar with Edward Tufte should check out his [fantastic books](https://www.edwardtufte.com/tufte/books_vdqi) and [courses on data visualizaton.](https://www.edwardtufte.com/tufte/courses)

(be sure to only include the category tags for the data you use!)

## Read in data

Read in one (or more) of the following datasets, using the correct R package and command.

  - eggs ⭐
  - abc_poll ⭐⭐
  - australian_marriage ⭐⭐
  - hotel_bookings ⭐⭐⭐
  - air_bnb  ⭐⭐⭐
  - us_hh ⭐⭐⭐⭐
  - faostat ⭐⭐⭐⭐⭐

For this challenge I will be working with the "USA Households\*.xlsx" data set.

```{r}
library(readxl)

# Reading the USA Households\*.xlsx data set and storing in a data frame

column_names = c("Year", "Household_Number_Thousands", "Total_Percent_Distribution", "Under $15,000", "$15,000 to $24,999", "$25,000 to $34,999", "35,000 to $49,999", "$50,000 to $74,999", "$75,000 to $99,999", "$100,000 to $149,999", "$150,000 to $199,999", "$200,000 and over", "Median_Income_Estimate", "Median_Income_MOE", "Mean_Income_Estimate", "Mean_Income_MOE")
usa_data <- read_excel("_data/USA Households by Total Money Income, Race, and Hispanic Origin of Householder 1967 to 2019.xlsx", col_names = column_names, skip = 5)
print(usa_data)
```

Since the “USA Households\*.xlsx” data set is in Excel format, I am using the 'readxl' package for reading the data. After reading, the data is stored in a dataframe “usa_data". The first three rows in the dataframe contains description about the data and the 4th and 5th row contains the column headings. I resolve this issue by skipping the first 5 rows while reading the data set and storing in a dataframe "usa_data" with the renamed column names.


### Briefly describe the data

The USA household data contains information on the mean and median income grouped by Race and Hispanic Origin of householder for the period 1967 - 2019. The data is split into 12 different categories based on Races and we have the total number of households surveyed in a given year along with the total percentage distribution (100 for all observations), percentage distribution for various income levels, and the mean and median (estimated and margin of error) income. For some races, data is not available for all the years in the period 1967 - 2019.


## Tidy Data and Mutate Variables (as needed)

Is your data already tidy, or is there work to be done? Be sure to anticipate your end result to provide a sanity check, and document your work here. Are there any variables that require mutation to be usable in your analysis stream? For example, do you need to calculate new values in order to graph them? Can string values be represented numerically? Do you need to turn any variables into factors and reorder for ease of graphics and visualization?


The data is not tidy and requires data cleaning. (Note: I renamed the column names while reading the data.) First, I removed the last 31 rows from the dataframe "usa_data" as they are just footnotes and not observations. 

```{r}
# Removing the last 31 rows as they are just footnotes and not observations
usa_data <- head(usa_data,-31)
print(usa_data)
```

Currently, the dataset does not have a separate column for "Race". The "Race" was mentioned in the "Year" column (the remaining columns were empty for such observations) and were inserted as separators for different race groups in the data. So, I created a new column for "Race" (muatated variable) and filled it with non-numerical values from "Year" column. I also filled the empty values in "Race" with the previous value in that column. Then, I removed the rows from the dataset which had Race value in the "Year" column.

```{r}
# Creating new column for Race and filling the empty values for Race with the previous value in that column

usa_data <- usa_data%>%
  mutate(Race = case_when(str_detect(Year,("([A-Z])")) ~ Year))%>%
  fill(Race, .direction = "down")

# Removing the rows from usa_data which has non-numerical values in Year column (these rows have Race value in the Year column and were inserted as separators for different Race groups)

usa_data <- usa_data%>%
  filter(!str_detect(Year,("([A-Z])")))

usa_data
```

Next, I removed the footnote number next to the year value and race value from the columns "Year" and "Race" respectively as they had no purpose in visualization.

```{r}
# Removing the footnote number next to the year value in the "Year" column

usa_data <- usa_data%>%
  mutate(Year = str_remove(Year, " .*"))

# Removing the footnote number next to the race value in the "Race" column

usa_data <- usa_data%>%
  mutate(Race = str_remove(Race, "[0-9]+"))

usa_data
```

Following that, I removed the "Total_Percent_Distribution" column form the dataset as the value was same (100) for all the observations and had no purpose in visualization.

```{r}
# Remove the "Total_Percent_Distribution" column as that value is 100 for all observations

usa_data <- usa_data%>%
  subset(select = -c(3))

usa_data
```

Finally, I reordered the columns in the dataframe in order to have "Race" as the first column followed by "Year" and the remaining columns.

```{r}
# Reorder the columns in the usa_data dataframe so that "Race" is the first column followed by "Year"

usa_data <- usa_data%>%
  subset(select=c(16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15))

usa_data
```

I checked for missing/null data in the "usa_data" dataframe and found that there are no NA or NULL values.

```{r}
#Check for missing/null data in the hotel_data
sum(is.na(usa_data))
sum(is.null(usa_data))
```

I found that there are few columns which have numerical values but datatype assigned as "character" Hence, I looked further into those columns.

```{r}
str(usa_data)
```

The datatype "character" columns "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE" have numerical values. I applied the table() to these columns to see which value is non-numerical and whether they can be modified or removed. The columns had few instances of "N" value indicating that the data may not be available. I decided to drop the observations with "N" value from the dataframe and changed the datatype to "numeric" for these columns.

```{r}
# Checking whether the columns "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE" have non-numerical values
col <- c("Household_Number_Thousands", "Mean_Income_Estimate","Mean_Income_MOE")
for (c in col){
    print(c)
    print(table(usa_data[,c]))
}
```

```{r}
# Remove rows from the dataset that have "N" value
usa_data <- usa_data%>%
  filter(across(everything(),~ . !="N"))
usa_data
```

```{r}
# Converting the datatype of "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE" columns from character to numeric
usa_data <- usa_data%>%
  mutate(Household_Number_Thousands = as.numeric(Household_Number_Thousands))%>%
  mutate(Mean_Income_Estimate = as.numeric(Mean_Income_Estimate))%>%
  mutate(Mean_Income_MOE = as.numeric(Mean_Income_MOE))
```



Sanity Check: Make sure that the "N" values are removed from the columns "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE".

```{r}
# Sanity Check: Check that the columns "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE" have no non-numerical values
col <- c("Household_Number_Thousands", "Mean_Income_Estimate","Mean_Income_MOE")
for (c in col){
    print(c)
    print(table(usa_data[,c]))
}
```

Sanity Check: Make sure that the range of years is from 1967 - 2019, there are 12 Race groups, and there are no footnote numbers.

```{r}
# Find number of distinct Year values
n_distinct(usa_data$Year)

# Sanity check: Check that the unique Year values range from 1967 - 2019 after data cleaning 
unique(usa_data$Year)
```


```{r}
# Find number of distinct Race values
n_distinct(usa_data$Race)

# Sanity check: Check that the unique Race values do not have any footnote numbers after data cleaning 
unique(usa_data$Race)
```

```{r}
#Summary of usa_data
library(summarytools)
print(summarytools::dfSummary(usa_data,
                        varnumbers = FALSE,
                        plain.ascii  = FALSE, 
                        style        = "grid", 
                        graph.magnif = 0.60, 
                        valid.col    = FALSE),
      method = 'render',
      table.classes = 'table-condensed')
```


**Summary of tidy data and mutate variables (as needed):**

After reading the data and renaming the columns, we have 383 rows and 16 columns in the dataframe. Out of the 383 rows, the last 31 rows are footnotes and are removed resulting in 352 rows and 16 columns. The first column “Year” has information on the Year and Race and Hispanic origin of householder. The race value in the first column is currently used as a separator for the different race groups in the data. Hence, I made a new column called “Race” and filled the column with the race value if available, else filled with the previous race value. We get a total of 12 distinct race groups. Following that, I removed the rows from the dataframe that had non-numerical values in the first column as these rows with the Race value were just used as a divider between race groups. This results in a dataframe of 340 rows and 17 columns. Now, we have separate columns for “Year” and “Race”. Next, I removed the footnote numbers next to the values in the “Year” and “Race” columns. I also removed the column “Total_Percent_Distribution” as the value is 100 for all observations and is not significant. If we add the percentage value for all 9 income levels in an observation it should add up to 100. Finally, I reordered the columns so that “Race” is the first column in the dataframe followed by “Year” and the remaining columns. I also made sure to check that the datatypes of the columns were correct. I noticed that the "character" columns "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE" had few instances of "N" value (indicating that the data may not be available). These columns are supposed to be "numeric". I decided to drop the observations (3 in this case) with "N" value from the dataframe and changed the datatype to "numeric" for these columns.

After cleaning the data, I end up with a dataframe of 337 observations and 16 columns/attributes. I did a sanity check to make sure that the columns "Household_Number_Thousands", "Mean_Income_Estimate", and "Mean_Income_MOE" have no non-numerical values, we have data for the period 1967 - 2019 and we have 12 race categories in total. Currently, I have not removed the observations with race value as "ALL RACES" as I am not sure whether they include the other race categories. I summarized the data using dfSummary() function and made sure that there are no duplicates or missing values in the data and the datatypes match.

## Visualization with Multiple Dimensions

In Challenge 5, I plotted a multivariate visualization using line plot representing the Mean Income for the Years 1967 - 2019 grouped by Race categories. I chose line plot as it is an effective method of displaying relationship between two variables when one of the two variables represents time (year in this case). I am adding ggplot functionality geom_point() and geom_smooth() as it makes it easier to analyze the trends.

```{r fig.height = 5, fig.width = 10}

# Line plot representing the Mean Income for the years 1967 - 2019 grouped by Race.
ggplot(usa_data, aes(y=Mean_Income_Estimate, x = Year, group = Race, color = Race)) + 
  #geom_line() +
  geom_point() +
  geom_smooth() +
  labs(title = "Mean Income for the years 1967 - 2019 grouped by Race", 
       y = "Mean Income", x = "Year") +
  theme(axis.text.x=element_text(angle=90, hjust=1))
```
Adding the geom_smooth() helps us to visualize the trends effectively. From the above visualization, we can observe that the mean income for "Asian" Race households is the highest. It is also evident that we have data for "Asian" Race households only from the year 1988. For the years 1967 - 1971, we have data only for the Races "ALL RACES", "BLACK" and "WHITE". "ALL RACES" is the only Race category for which we have data observations for all the years from 1967 - 2019. Hence, it would be difficult to make comparisons among different Race categories for the period 1967 - 2019.

```{r}
# Mutate the 'Race' variable to reduce number of Race categories.
usa_data <- usa_data%>%
  mutate(Race = case_when(str_detect(Race, 'ALL') ~ 'ALL RACES',
         str_detect(Race, 'WHITE') ~ 'WHITE',
         str_detect(Race, 'BLACK') ~ 'BLACK',
         str_detect(Race, 'HISPANIC') ~ 'HISPANIC',
         str_detect(Race, 'ASIAN') ~ 'ASIAN'))
table(usa_data$Race)
```


The above visualization may be a little difficult to interpret and analyze as there are many Race categories. One solution was to group the 12 Race categories into 5 Race categories: ALL RACES, WHITE, BLACK, HISPANIC, ASIAN. This makes the visualization simplified as there are lesser Race categories. I plot the same line plot with the modified data.

```{r fig.height = 5, fig.width = 10}

# Line plot representing the Mean Income for the years 1967 - 2019 grouped by Race.
ggplot(usa_data, aes(y=Mean_Income_Estimate, x = Year, group = Race, color = Race)) + 
  #geom_line() +
  geom_point() +
  geom_smooth() +
  labs(title = "Mean Income for the years 1967 - 2019 grouped by Race", 
       y = "Mean Income", x = "Year") +
  theme(axis.text.x=element_text(angle=90, hjust=1))
```
From the above visualization, it is clear that "ASIAN" race households have the highest mean income followed by "WHITE" race households.


I am plotting a multivariate bar graph representing the distribution of household numbers for years 1967 - 2019 using faceting. I am using bar plots as I want to visualize the distribution of categorical variables (Year and Household Numbers). Faceting enables us to view the distribution of household numbers for each Race category in individual subplots. This makes it easy for us to compare the distributions across Race categories.

```{r fig.height = 15, fig.width = 20}
# Bar graph representing the distribution of household numbers for years 1967 - 2019.

library(ggplot2)

ggplot(usa_data, aes(x = Year, y = Household_Number_Thousands)) + 
  geom_bar(fill="#00BFC4", stat = "identity") +
  facet_wrap(~Race) +
  labs(title = "Distribution of household numbers for years 1967 - 2019", 
       y = "Household Number in Thousands", x = "Year") +
  theme(axis.text.x=element_text(angle=90, hjust=1))
```
From the above visualization, we can observe that the Household number in thousands is highest for the "WHITE" race. This is possible as the population of "WHITE" race in United States of America is higher. We can also observe that years 2013 and 2017 have the highest number of Household numbers for all 5 Race categories. Need to research more on the reason behind this.


When I render and view the visualizations in the blog format I notice that the final visualization using faceting has tiny font and not visually appealing for readers (the axis labels do not seem to be clear). Maybe in future I should perform faceting for a smaller subset of data (for example years 2000 - 2019 rather than 1967 - 2019).